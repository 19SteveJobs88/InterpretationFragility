# Interpretation of Neural Network is Fragile

## The large scale results of attack methods against four famous feature-attribution methods
![alt text](https://github.com/amiratag/InterpretationFragility/blob/master/pictures/SaliencyMethodsComparison.png)

## Examples of targeted attack for semantically meaningful change in feature-importance
![alt text](https://github.com/amiratag/InterpretationFragility/blob/master/pictures/SemanticChange.png)

## Attack examples on Deep Taylor Decomposition
![alt text](https://github.com/amiratag/InterpretationFragility/blob/master/pictures/DTD_examples.png)
