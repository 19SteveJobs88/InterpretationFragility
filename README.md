# Interpretation of Neural Network is Fragile

**Please cite the following work if you use this benchmark or the provided tools or implementations:**

    [1] Amirata Ghorbani, Abubakar Abid, James Zou
        Interpretation of Neural Network is Fragile
        arXiv:1710.10547
## The large scale results of attack methods against four famous feature-attribution methods
![alt text](https://github.com/amiratag/InterpretationFragility/blob/master/pictures/SaliencyMethodsComparison.png)

## Examples of targeted attack for semantically meaningful change in feature-importance
![alt text](https://github.com/amiratag/InterpretationFragility/blob/master/pictures/SemanticChange.png)

## Attack examples on Deep Taylor Decomposition
![alt text](https://github.com/amiratag/InterpretationFragility/blob/master/pictures/DTD_examples.png)
